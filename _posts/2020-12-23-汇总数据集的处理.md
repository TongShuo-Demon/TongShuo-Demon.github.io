---
title: 数据集的处理集中总结
description: 根据github上面需要处理一个VOC格式数据集合，然后再加上之前学习yolov5的时候使用的一个JSON格式数据集，所以今天统一总结一下。
categories:
 - 深度学习
tags:
---

# VOC数据集介绍

## VOC数据集（Pascal Visual Object Classes）

在这个数据集里面一共有20类，文件目录结构如下所示：

```
└── VOC2007
    ├── Annotations   #存放xml文件，与JPEGImages中的图片一一对应，解释图片的内容等等
    ├── ImageSets  #目录下存放的都是txt文件，文件中每一行包含一个图片的名称，末尾会加上±1表示正负样本
    │   ├── Layout
    │   ├── Main
    │   └── Segmentation
    ├── JPEGImages  #存放源图片
    ├── SegmentationClass
    └── SegmentationObject
```



## 脚本文件xml2txt.py

以下文件是通过github下载的，实现的功能就是将xml文件转成txt文件。以下脚本文件要更改的是将classes和数据集的根目录(rootpath)更改成适应自己的数据集的格式。

```python
'''
2020/6/15,标注文件转换xml转txt（vol to yolo）转完后需添加labels文件，即数字序号对应的标签名。
'''
import xml.etree.ElementTree as ET
import pickle
import os
from os import listdir, getcwd
from os.path import join

classes = ["aeroplane", "bicycle", "bird", "boat", "bottle",
        "bus", "car", "cat", "chair", "cow",
        "diningtable", "dog", "horse", "motorbike", "person",
        "pottedplant", "sheep", "sofa", "train", "tvmonitor"]

def convert(size, box):
    dw = 1./(size[0])
    dh = 1./(size[1])
    x = (box[0] + box[1])/2.0 - 1
    y = (box[2] + box[3])/2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    if w>=1:
        w=0.99
    if h>=1:
        h=0.99
    return (x,y,w,h)

def convert_annotation(rootpath,xmlname):
    xmlpath = rootpath + '/Annotations'
    xmlfile = os.path.join(xmlpath,xmlname)
    with open(xmlfile, "r", encoding='UTF-8') as in_file:
      txtname = xmlname[:-4]+'.txt'
      print(txtname)
      txtpath = rootpath + '/worktxt'#生成的.txt文件会被保存在worktxt目录下
      if not os.path.exists(txtpath):
        os.makedirs(txtpath)
      txtfile = os.path.join(txtpath,txtname)
      with open(txtfile, "w+" ,encoding='UTF-8') as out_file:
        tree=ET.parse(in_file)
        root = tree.getroot()
        size = root.find('size')
        w = int(size.find('width').text)
        h = int(size.find('height').text)
        out_file.truncate()
        for obj in root.iter('object'):
            difficult = obj.find('difficult').text
            cls = obj.find('name').text
            if cls not in classes or int(difficult)==1:
                continue
            cls_id = classes.index(cls)
            xmlbox = obj.find('bndbox')
            b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))
            bb = convert((w,h), b)
            out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')


if __name__ == "__main__":
    rootpath='/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007'
    xmlpath=rootpath+'/Annotations'
    list=os.listdir(xmlpath)
    for i in range(0,len(list)) :
        path = os.path.join(xmlpath,list[i])
        if ('.xml' in path)or('.XML' in path):
            convert_annotation(rootpath,list[i])
            print('done', i)
        else:
            print('not xml file',i)
```

### 分割数据集

因为VOC数据集是将所有的数据集放置在一起的，但是实际使用的话是需要进行分割的，一般情况下都是9：1或者8：2进行分割。

实际使用的话只需要修改root_dir根目录。

```python
#数据集划分
import os
import random

root_dir='/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/'

## 0.7train 0.1val 0.2test
trainval_percent = 0.8
train_percent = 0.7
xmlfilepath = root_dir+'Annotations'
txtsavepath = root_dir+'ImageSets/Main'
total_xml = os.listdir(xmlfilepath)

num = len(total_xml)  # 100
list = range(num)
tv = int(num*trainval_percent)  # 80
tr = int(tv*train_percent)  # 80*0.7=56
trainval = random.sample(list, tv)
train = random.sample(trainval, tr)

ftrainval = open(root_dir+'ImageSets/Main/trainval.txt', 'w')
ftest = open(root_dir+'ImageSets/Main/test.txt', 'w')
ftrain = open(root_dir+'ImageSets/Main/train.txt', 'w')
fval = open(root_dir+'ImageSets/Main/val.txt', 'w')

for i in list:
    name = total_xml[i][:-4]+'\n'
    if i in trainval:
        ftrainval.write(name)
        if i in train:
            ftrain.write(name)
        else:
            fval.write(name)
    else:
        ftest.write(name)

ftrainval.close()
ftrain.close()
fval.close()
ftest .close()
```



## 提取数据集

以下是提取train数据集，实际使用的话仅仅需要更改路径就可以.

实现功能：将训练集和验证集放置在一起，测试集单独放置，结合之前的xml转TXT文件，可以同时实现提取xml、txt、jpg三类文档。

```python
# -*- coding:UTF-8 -*-
import shutil
 
root_path = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/'
f_txt = open(root_path+'ImageSets/Main/trainval.txt', 'r')
f_train_jpg = root_path+'new_voc/train/images/'
f_train_xml = root_path+'new_voc/train/labels/'
f_train_txt = root_path+'new_voc/train/labels_txt/'

f_test =  open(root_path+'ImageSets/Main/test.txt', 'r')    
f_test_jpg = root_path+'new_voc/test/images/'
f_test_xml = root_path+'new_voc/test/labels/'    
f_test_txt = root_path+'new_voc/test/labels_txt/'    
    
#处理训练集与验证集    
context = list(f_txt)
for imagename in context:
    imagename = imagename[0:6]
    imagename_jpg = imagename + '.jpg'
    imagename_xml = imagename + '.xml'
    imagename_txt = imagename + '.txt'
    imagepath_jpg = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/JPEGImages/'+ imagename_jpg
    imagepath_xml = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/Annotations/'+ imagename_xml
    imagepath_txt = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/worktxt/'+ imagename_txt
    
    shutil.copy(imagepath_jpg,f_train_jpg)
    shutil.copy(imagepath_xml,f_train_xml)
    shutil.copy(imagepath_txt,f_train_txt)
    
#处理测试集   
context_test = list(f_test)
for imagename_test in context_test:
    imagename_test = imagename_test[0:6]
    imagename_test_jpg = imagename_test + '.jpg'
    imagename_test_xml = imagename_test + '.xml'
    imagename_test_txt = imagename_test + '.txt'
    imagepath_test_jpg = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/JPEGImages/'+ imagename_test_jpg
    imagepath_test_xml = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/Annotations/'+ imagename_test_xml
    imagepath_test_txt = '/home/demon/PycharmProjects/mobile-yolov5-pruning-distillation/data/VOC/VOCdevkit/VOC2007/worktxt/'+ imagename_test_txt
    shutil.copy(imagepath_test_jpg, f_test_jpg)
    shutil.copy(imagepath_test_xml, f_test_xml)
	shutil.copy(imagepath_test_txt, f_test_txt)

    # 删除训练集和验证集，剩余图片为测试集
    # os.remove(imagepath)
    #处理Annotations同理只需将.jpg改为.xml
```



# flir红外数据集

## 数据集文件目录

详细了解看[官网介绍](https://www.flir.cn/oem/adas/adas-dataset-form/)。

数据集的文件格式如下：

```.
├── train
│   ├── Annotated_thermal_8_bit
│   ├── RGB
│   ├── thermal_16_bit
│   ├── thermal_8_bit
│   └── thermal_annotations.json
├── val
│   ├── Annotated_thermal_8_bit
│   ├── RGB
│   ├── thermal_16_bit
│   ├──  thermal_8_bit
│   └── thermal_annotations.json
└── video
    ├── Annotated_thermal_8_bit
    ├── RGB
    ├── thermal_16_bit
    ├── thermal_8_bit
    └── thermal_annotations.json
```

其实我第第一次下载这个数据集的时候感觉很奇怪，这个json格式文件到底是什么鬼？后来百度了解了一下，今天就对这个数据集进行统一的整理。



## json格式的文件

JSON ( JavaScript Object Notation) ，是一种数据交互格式。是由道格拉斯·克罗克福特（Douglas Crockford）发明了JSON 这种超轻量级的数据交换格式。



## json格式转为xml

这里是通过命令行的形式来使用的，如下所示：

`python3 <代码文件名> <json文件路径> <txt文件保存路径>`

这里主要注意一点就是，一定要填写路径的文件夹名字。

代码里面的图片大小应该要根据实际的情况进行更改，同时也要根据实际情况进行更改。

```python
from __future__ import print_function
import argparse
import glob
import os
import json

if __name__ == '__main__':
    # 命令行打印参数
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "path", help='Directory of json files containing annotations')  # json文件路径
    parser.add_argument(
        "output_path", help='Output directory for image.txt files')  # 生成的txt保存路径
    args = parser.parse_args()

    # os.path.join 合并路径
    # glob.glob 获取所有匹配的路径
    json_files = sorted(glob.glob(os.path.join(args.path, '*.json')))  # 得到json文件路径下的所有json文件

    for json_file in json_files:
        with open(json_file) as f:
            data = json.load(f)  # 将json文件转化为字典
            images = data['images']
            annotations = data['annotations']

            # 图片w h，为归一化作准备
            width = 640.0
            height = 512.0

            for i in range(0, len(images)):
                converted_results = []
                for ann in annotations:
                    if ann['image_id'] == i and (ann['category_id'] == 3 or ann['category_id'] == 1):  # FLIR数据集中只有1-3
                        cat_id = int(ann['category_id'])

                        # letf top为左下角坐标 bbox_width bbox_height为目标框长宽
                        # 将bbox数值转化为float类型
                        left, top, bbox_width, bbox_height = map(float, ann['bbox'])

                        # Yolo的id从0开始，FILIR从1开始
                        # if cat_id == 1:
                        #     cat_id = 0
                        #     print("truck /n \n")
                        # elif cat_id == 3:
                        #     cat_id = 1
                        cat_id -= 1

                        # 求中心点坐标
                        x_center, y_center = (
                            left + bbox_width / 2, top + bbox_height / 2)

                        # 归一化
                        x_rel, y_rel = (x_center / width, y_center / height)
                        w_rel, h_rel = (bbox_width / width, bbox_height / height)
                        converted_results.append(
                            (cat_id, x_rel, y_rel, w_rel, h_rel))

                image_name = images[i]['file_name']

                # 这里image_name是thermal_8_bit/FLIR_xxxxx.jpeg格式,我们文件名只需要FLIR_xxxxx部分
                image_name = image_name[14:-5]

                print(image_name)  # 验证是名称否正确

                file = open(args.output_path + str(image_name) + '.txt', 'w+')
                file.write('\n'.join('%d %.6f %.6f %.6f %.6f' % res for res in converted_results))
                file.close()
```



# coco数据集格式

COCO的全称是Common Objects in Context，是微软团队提供的一个可以用来进行图像识别的数据集。MS COCO数据集中的图像分为训练、验证和测试集。

```python
.
├── annotations
├── images
│   ├── train2017
│   └── val2017
└── labels
    ├── train2017
    └── val2017
```

这个数据集里面同时拥有json格式的文件与TXT标注文件。













[参考文件](https://github.com/DLLXW/objectDetectionDatasets)



















