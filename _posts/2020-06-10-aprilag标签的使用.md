---
title: apriltag在Ubuntu下面使用
description: 在实际比赛过程中需要使用标签进行相机位姿估计
categories:
 - RM
 - SLAM
tags:
---

# 背景

在RM比赛过程中，需要用到贴在环形高地上的apriltag标签（16h5）,然后通过apriltag标签得到相机位姿，进而得到检测到的飞镖在世界坐标系下面的坐标。但是在opencv里面并没有集成apriltag的库，所以必须安装相关的库才可以。

# 编译aprilltag

访问apriltag库的[github](https://github.com/AprilRobotics/apriltag)，将此开源库下载下来，然后进行编译，指令如下所示

```powershell
cmake .                #进入目录
sudo make install      #进行安装   
```

默认安装会将标头放置在/ usr / local / include中，并将共享库放置在/ usr / local / lib中。其他详细信息可以看README。

其实，一开始我用指令测试是否安装成功时候，没有测试成功，然后我就想直接用他的.c和.h文件，尝试了各种方法，最后发现完全可以直接放在clion(我在Ubuntu下面使用的编译器)下面使用。



## 在其他工程文件使用该库

很简单只要在cmakelist.txt里面修改添加一下内容就可以,

```powershell
target_link_libraries(Radar /usr/local/lib/libapriltag.so
        /usr/local/lib/libapriltag.so.3 /usr/local/lib/libapriltag.so.3.1.0)
```

这三个库就是我们编译apriltag库生成的三个共享库。这样改过后我们在工程文件里面使用了。



##  apriltag检测原理

主要分为几个步骤：([参考](https://blog.csdn.net/qq_42238850/article/details/89044895?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase#t3))

1,**线段聚类**（clustering）

2,**图像分割**

3.**深度优先搜索**（深度为四的DFS确定四边形）

4,**关键角点阈值筛选**（Thresh）

如果想要具体去研究的话，必须去看论文[2011](https://april.eecs.umich.edu/papers/details.php?name=olson2011tags)   [2016 ](https://april.eecs.umich.edu/papers/details.php?name=wang2016iros)   [2013](https://april.eecs.umich.edu/papers/details.php?name=richardson2013iros)描述的是相机校准方面的

[2019](https://april.eecs.umich.edu/papers/details.php?name=krogius2019iros)  描述的是基准标签的灵活布局



## apriltag 位姿估计



```c++
 tvec <<pose.t->data[0],pose.t->data[1],pose.t->data[2];                 //tag相对于相机的位姿

        rvec <<pose.R->data[0],pose.R->data[1],pose.R->data[2],
                pose.R->data[3],pose.R->data[4],pose.R->data[5],
                pose.R->data[6],pose.R->data[7],pose.R->data[8];
```



上面的变换矩阵指的是**二维码坐标系到相机坐标系下面**的，如果将其用作为相机的位姿估计R和T，还需要变换：

![2020-06-10 10-37-57屏幕截图.png](http://ww1.sinaimg.cn/large/006lMPXUgy1gfmzstn5swj309c01rdfp.jpg)

在这里为什么使用转置矩阵呢，那是因为旋转矩阵是正交矩阵，正交矩阵的转置等于矩阵的逆。



对于位姿估计这边，我断断续续搞了快一周，，首先对于tag的坐标系我不确定，实际上**tag的坐标系和相机一样**，只是平移向量不一样。还有比如说相机 的位姿具体是什么意思，在什么坐标系下面的，整的我很乱。

实际上，**T_w_c表示的相机坐标系到世界坐标系的变换，也就是相机的位姿**，其平移部分就是相机原点在世界坐标系下的坐标。

![2020-06-10 11-12-48屏幕截图.png](http://ww1.sinaimg.cn/large/006lMPXUgy1gfn0thvnbtj309u01mt8i.jpg)

下面的公式主要表达的是相机坐标系变换到世界坐标系：

![19D098B50ADB8AC7D7910CA49C4BC77E.png](http://ww1.sinaimg.cn/large/006lMPXUgy1gfn3j2xgv1j30ua0dfac0.jpg)



其实对于姿态这部分，涉及到很多知识，比如欧拉角、四元数、旋转向量等等。

可以看看这位兄弟的[博客](https://blog.csdn.net/shenxiaolu1984/article/details/50639298)

## homography method



他的中文意思是单应性矩阵，这里说的单应性矩阵主要是指平面单应性矩阵，在三轴坐标中XYZ，Z=1这个有点类似于三维的齐次坐标。单应性矩阵主要用来解决两个问题，

* 真实世界中的一个平面与他对应图像的透射变换‘
* 通过透视变换实现图像从一种视图变换到另外一种视图

对于三维空间中两张图片可以通过一个矩阵确定他们之间的关系，这个就是单应性矩阵。

![undefined](http://ww1.sinaimg.cn/large/006lMPXUgy1gfokriqsahj309p02h3yb.jpg)

单应性在计算机视觉领域是一个非常重要的概念，它在**图像校正、图像拼接、相机位姿估计、视觉SLAM**等领域有非常重要的作用。

具体原理可以[参考这个](https://blog.csdn.net/u014527548/article/details/88028811),其实也就是这位大兄弟翻译了2011年那篇文章。

![h.png](http://ww1.sinaimg.cn/large/006lMPXUgy1gfona3gfq9j30s215safj.jpg)





## 添加位姿代码

位姿估计这里面用到了两种方法，其中一种是homography。

在这段代码里面 

info.tagsize 表示标识的实际尺寸
info.fx  info.fy  info.cx   info.cy四个参数表示的是内参矩阵的几个参数。 

以下代码参考[参考链接](https://blog.csdn.net/qq_42238850/article/details/89044895?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase)

```c++
#include <iostream>
#include "opencv2/opencv.hpp"
#include <fcntl.h>
#include <errno.h> 
#include <cmath>
#include <cstring>
#include <vector>
#include <list>
#include <eigen3/Eigen/Dense>

extern "C" {
#include "apriltag_pose.h"
#include "apriltag.h"
#include "tag36h11.h"
#include "tag25h9.h"
#include "tag16h5.h"
#include "tagCircle21h7.h"
#include "tagCircle49h12.h"
#include "tagCustom48h12.h"
#include "tagStandard41h12.h"
#include "tagStandard52h13.h"
#include "common/getopt.h"
#include "common/homography.h"
}
using namespace std;
using namespace cv;

#ifndef PI
const double PI = 3.14159265358979323846;
#endif
const double TWOPI = 2.0*PI;
/**
 * 定义了角度归一化函数，角度范围统一输出范围是[-pi,pi].
 **/
inline double standardRad(double t) {
  if (t >= 0.) {
    t = fmod(t+PI, TWOPI) - PI;
  } else {
    t = fmod(t-PI, -TWOPI) + PI;
  }
  return t;
}


    int main(int argc, char *argv[])
{
    getopt_t *getopt = getopt_create();

    getopt_add_bool(getopt, 'h', "help", 0, "Show this help");
    getopt_add_bool(getopt, 'd', "debug", 1, "Enable debugging output (slow)");
    getopt_add_bool(getopt, 'q', "quiet", 0, "Reduce output");
    getopt_add_string(getopt, 'f', "family", "tag36h11", "Tag family to use");
    getopt_add_int(getopt, 't', "threads", "1", "Use this many CPU threads");
    getopt_add_double(getopt, 'x', "decimate", "2.0", "Decimate input image by this factor");
    getopt_add_double(getopt, 'b', "blur", "0.0", "Apply low-pass blur to input");
    getopt_add_bool(getopt, '0', "refine-edges", 1, "Spend more time trying to align edges of tags");

    if (!getopt_parse(getopt, argc, argv, 1) ||
            getopt_get_bool(getopt, "help")) {
        printf("Usage: %s [options]\n", argv[0]);
        getopt_do_usage(getopt);
        exit(0);
    }
    // Initialize camera
    VideoCapture cap(0);
    if (!cap.isOpened()) {
        cerr << "Couldn't open video capture device" << endl;
        return -1;
    }
    // Initialize tag detector with options
    apriltag_family_t *tf = NULL;
    const char *famname = getopt_get_string(getopt, "family");
    if (!strcmp(famname, "tag36h11")) {
        tf = tag36h11_create();
    } else if (!strcmp(famname, "tag25h9")) {
        tf = tag25h9_create();
    } else if (!strcmp(famname, "tag16h5")) {
        tf = tag16h5_create();
    } else if (!strcmp(famname, "tagCircle21h7")) {
        tf = tagCircle21h7_create();
    } else if (!strcmp(famname, "tagCircle49h12")) {
        tf = tagCircle49h12_create();
    } else if (!strcmp(famname, "tagStandard41h12")) {
        tf = tagStandard41h12_create();
    } else if (!strcmp(famname, "tagStandard52h13")) {
        tf = tagStandard52h13_create();
    } else if (!strcmp(famname, "tagCustom48h12")) {
        tf = tagCustom48h12_create();
    } else {
        printf("Unrecognized tag family name. Use e.g. \"tag36h11\".\n");   //user does not set the family type of Tags 
        exit(-1);                                                           //default type:  tf = tag36h11_create()  
    }                   


    apriltag_detector_t *td = apriltag_detector_create();              //set some parameters
    apriltag_detector_add_family(td, tf);                              //set parttern recongnize of the specific tag family
    td->quad_decimate = getopt_get_double(getopt, "decimate");       
    td->quad_sigma = getopt_get_double(getopt, "blur");
    td->nthreads = getopt_get_int(getopt, "threads");
    td->debug = getopt_get_bool(getopt, "debug");
    td->refine_edges = getopt_get_bool(getopt, "refine-edges");
    
    Mat frame, gray;
    
    /***********输入标定的相机参数*************/
    apriltag_detection_info_t info;     // parameters of the camera calibrations 在这里把标定得到的四元参数输入到程序里
     info.tagsize = 0.056; //标识的实际尺寸
     info.fx = 652.894;
     info.fy = 651.487;
     info.cx = 301.857;
     info.cy = 237.548;

    while (true) {
        cap >> frame;
        cvtColor(frame, gray, COLOR_BGR2GRAY);

        // Make an image_u8_t header for the Mat data , and turn the gray image into the candidate of the tags waiting to be recongnized(&im)
        image_u8_t im = { .width = gray.cols,        
            .height = gray.rows,
            .stride = gray.cols,
            .buf = gray.data
        };                          

        zarray_t *detections = apriltag_detector_detect(td, &im);    //parttern recongnize to start
        cout << zarray_size(detections) << " tags detected" << endl;

        // Draw detection outlines
        for (int i = 0; i < zarray_size(detections); i++) {
            apriltag_detection_t *det;                       //
            zarray_get(detections, i, &det);
            line(frame, Point(det->p[0][0], det->p[0][1]),
                     Point(det->p[1][0], det->p[1][1]),
                     Scalar(0, 0xff, 0), 2);
            line(frame, Point(det->p[0][0], det->p[0][1]),
                     Point(det->p[3][0], det->p[3][1]),
                     Scalar(0, 0, 0xff), 2);
            line(frame, Point(det->p[1][0], det->p[1][1]),
                     Point(det->p[2][0], det->p[2][1]),
                     Scalar(0xff, 0, 0), 2);
            line(frame, Point(det->p[2][0], det->p[2][1]),
                     Point(det->p[3][0], det->p[3][1]),
                     Scalar(0xff, 0, 0), 2);
            
            stringstream ss;
            ss << det->id;
            String text = ss.str();
            
         
           /*********加入位姿估计函数**********/
            info.det = det;  //det-->info
			apriltag_pose_t pose;
            estimate_pose_for_tag_homography(&info, &pose);
			//double err = estimate_tag_pose(&info, &pose);
         /**********将欧拉角转换成度为坐标，并归一化到[-pi,pi]范围内 ********/     
      double yaw = 180*standardRad(atan2(pose.R->data[3], pose.R->data[0]));
      double pitch=180*standardRad(sin(pose.R->data[6]));
      double roll=180*standardRad(atan2(pose.R->data[7],pose.R->data[8]));
             yaw=yaw/PI;
             pitch=pitch/PI;
             roll=roll/PI;    
			cout<<"THE 3D POSE:"<<"x= "<<pose.t->data[0]<<"  "<<"y= "<<pose.t->data[1]<<" "<<"z= "<<pose.t->data[2]<<endl;  //t output
            /************输出三维位置坐标信息***************/ 
                   cout<<"yaw: "<<yaw<<"'"<<endl;
                   cout<<"pitch: "<<pitch<<"'"<<endl;
                   cout<<"roll: "<<roll<<"'"<<endl;    
             /*************输出3个欧拉角数据****************/
        
		
		  int fontface = FONT_HERSHEY_SCRIPT_SIMPLEX;
          double fontscale = 1.0;
          int baseline;
          Size textsize = getTextSize(text, fontface, fontscale, 2,
                                            &baseline);
            putText(frame, text, Point(det->c[0]-textsize.width/2,
                                       det->c[1]+textsize.height/2),
                    fontface, fontscale, Scalar(0xfhomography methodf, 0x99, 0), 2);
        }
        zarray_destroy(detections);
        imshow("Tag Detections", frame);
        if (waitKey(25) >= 0)
            break;}
    apriltag_detector_destroy(td);

    if (!strcmp(famname, "tag36h11")) {
        tag36h11_destroy(tf);
    } else if (!strcmp(famname, "tag25h9")) {
        tag25h9_destroy(tf);
    } else if (!strcmp(famname, "tag16h5")) {
        tag16h5_destroy(tf);
    } else if (!strcmp(famname, "tagCircle21h7")) {
        tagCircle21h7_destroy(tf);
    } else if (!strcmp(famname, "tagCircle49h12")) {
        tagCircle49h12_destroy(tf);
    } else if (!strcmp(famname, "tagStandard41h12")) {
        tagStandard41h12_destroy(tf);
    } else if (!strcmp(famname, "tagStandard52h13")) {
        tagStandard52h13_destroy(tf);
    } else if (!strcmp(famname, "tagCustom48h12")) {
        tagCustom48h12_destroy(tf);
    }
    getopt_destroy(getopt);
    return 0;
}

```





